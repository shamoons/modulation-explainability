\documentclass{ELSP}
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
	\usepackage[]{microtype}
	\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\IfFileExists{parskip.sty}{%
	\usepackage{parskip}
}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
	pdfcreator={ELSP}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
	\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{color}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{geometry}
\geometry{a4paper,top=2.5cm,bottom=1.9cm,left=1.75cm,right=1.75cm,headsep=12px}
\usepackage{float}
\usepackage{enumerate}
\usepackage{stfloats}
\usepackage{ragged2e}
\usepackage{titlesec}

\titleformat{\section}[hang]
  {\fontsize{12pt}{12pt}\selectfont\bfseries\color[RGB]{0,131,255}} 
  {\thesection}{0.5em}{}

\titleformat{\subsection}[hang]
  {\fontsize{12pt}{12pt}\selectfont\emph} 
  {\thesubsection}{0.5em}{}

\titleformat{\subsubsection}[hang]
  {\fontsize{12pt}{12pt}\selectfont} 
  {\thesubsubsection}{0.5em}{}

\setlength{\parindent}{2em}
\setlength{\baselineskip}{17pt}
\setlength{\parskip}{12pt}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{Research Article}}}
\fancyhead[L]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{IEEE Transactions on Wireless Communications}}}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{1.4pt}
\fancypagestyle{firstpage}
{
	\fancyhf{}
	\setlength{\headsep}{6px}
	\fancyhead[R]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{IEEE Transactions on Wireless Communications}}}
	\fancyhead[L]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{Research Article}}}
	\fancyfoot[L]{\sffamily \footnotesize Author {\em et al}. IEEE Transactions on Wireless Communications 2024 (Issue): XXXX}
	\renewcommand{\headrulewidth}{1.4pt}
}

\captionsetup{labelfont={bf},labelformat={default},labelsep=period,margin=4em,format=plain}

\begin{document}

\thispagestyle{firstpage}

\let\thefootnote\relax
\footnotetext{
\newline
\newline
	\begin{minipage}[h]{0.15\linewidth}
	\includegraphics{fig/cc.png}
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.8\linewidth}
		\footnotesize{Copyright©2024 by the authors. Published by IEEE. 
			This work is licensed under a Creative Commons Attribution 4.0 
			International License, which permits unrestricted use, distribution, 
			and reproduction in any medium provided the original work is properly cited}
	\end{minipage}
}

\setstretch{1.24}
\begin{flushleft}
{\sffamily \small \noindent {Research Article $\mid$ Received 15 March 2024; Accepted 1 April 2024; Published 15 April 2024}}\\
{\sffamily\small{https://doi.org/10.1109/TWC.2024.XXXX}}

\papertitle{Constellation Diagram Augmentation and Perturbation-Based Explainability for Automatic Modulation Classification}

\authorname{Anonymous} {Author} {1}
\textbf{and} 
\authornameCorres{Anonymous} {Author}{1}{*}

\formatintroduction{1}{Department of Electrical Engineering, University, City, Country}

\authoremail{Correspondence author(s)} {E-mail: anonymous@university.edu}
\end{flushleft}

\noindent\textbf{\textcolor[RGB]{0,131,255}{Highlights:}}\\
\newline
\begin{itemize}
    \item Novel multi-task learning framework combining modulation classification and SNR estimation
    \item Enhanced constellation diagram representation with curriculum-based learning
    \item Perturbation-based explainability revealing critical signal regions
    \item Comprehensive evaluation on RadioML 2018.01A dataset with state-of-the-art results
\end{itemize}

\noindent\textbf{\textcolor[RGB]{0,131,255}{Abstract:}} 
Automatic Modulation Classification (AMC) is a cornerstone in ensuring the adaptability and efficiency of modern wireless communication systems. In this paper, we present a novel framework that combines multi-task learning with perturbation-based explainability to address both performance and interpretability challenges in AMC. By transforming the I/Q signal data into enriched constellation diagrams and employing a ResNet-based architecture, our model simultaneously classifies modulation schemes and estimates Signal-to-Noise Ratio (SNR) buckets, leveraging shared feature representations for improved generalization. To enhance interpretability, we systematically perturb high- and low-intensity regions of the constellation diagrams, analyzing their impact on classification accuracy and using the Perturbation Impact Score (PIS) metric. Our experimental evaluation on the RadioML 2018.01A dataset demonstrates the robustness of the proposed framework, achieving high accuracy across diverse modulation types even under challenging noise conditions. Additionally, perturbation analysis reveals critical regions in the constellation diagrams that drive model decisions, offering actionable insights for further optimization.

\noindent\textbf{\textcolor[RGB]{0,131,255}{Keywords:}} 
Automatic Modulation Classification, Deep Learning, Constellation Diagrams, Multi-task Learning, Explainable AI, Signal Processing, Wireless Communications, Neural Networks, SNR Estimation, Perturbation Analysis

\section{Introduction}
Automatic Modulation Classification (AMC) [1] [2] [3] is a fundamental task in wireless communication, enabling the identification of modulation schemes critical for signal decoding, interference mitigation, and dynamic spectrum management. AMC has far-reaching applications across domains such as cognitive radios, public safety, and military operations, where accurate and timely modulation classification directly impacts reliability, efficiency, and security.

Traditional approaches to AMC, including methods based on fourth-order cumulants and Artificial Neural Networks (ANNs) [4], have historically laid the foundation for this field. While these techniques achieved moderate success in controlled settings, their reliance on hand-engineered features and limited adaptability to complex and noisy environments restricted their applicability in real-world scenarios. With the advent of deep learning, Convolutional Neural Networks (CNNs) have demonstrated superior performance in AMC by leveraging their ability to learn rich feature representations directly from raw or preprocessed data [2]. However, despite their high accuracy, these models often operate as "black boxes," providing limited insight into their decision-making processes—a critical drawback in safety-critical applications where trust and transparency are paramount.

The growing need to understand and trust model decisions has driven interest in explainability techniques. Recent advancements, such as Concept Bottleneck (CB) models [5], have aimed to bridge the gap between performance and interpretability in AMC. While CB models have shown promise in explaining model decisions and even classifying modulation schemes unseen during training, they do not address how specific input features or perturbations affect classification accuracy. This gap in understanding limits the deployment of AMC models in high-stakes applications, where decision transparency is essential for regulatory compliance and operational reliability.

In this work, we propose a novel framework that combines constellation diagram augmentation with perturbation-based explainability to enhance the accuracy, robustness, and interpretability of deep learning-based AMC models. Our approach systematically investigates the impact of perturbations on constellation diagrams, identifying critical regions that drive model predictions. By integrating multi-task learning, we simultaneously predict modulation types and SNRs. This addresses the dual needs of modulation classification and channel quality estimation in real-world communication systems.

The key contributions of this work are as follows:

\begin{itemize}
    \item \textbf{Multi-Task Learning for Modulation and SNR Classification:} We introduce a multitask learning framework that jointly predicts the modulation type and SNR, enhancing the model's utility in dynamic wireless environments. This dual-task approach is particularly beneficial for applications requiring adaptive spectrum management and interference mitigation.
    
    \item \textbf{Constellation Diagram Augmentation:} We propose novel augmentations to traditional constellation diagrams, transforming them into rich visual representations that improve classification robustness, especially for complex modulation schemes under challenging noise conditions.
    
    \item \textbf{Perturbation-Based Explainability:} To improve interpretability, we employ perturbation-based methods to visualize the impact of specific regions of the constellation diagram on model predictions. This approach provides actionable insights into the features that drive classification decisions, enhancing trust in model outputs.
    
    \item \textbf{Security Implications and Public Safety Applications:} By quantifying the relationship between perturbation levels and classification performance, we reveal the robustness of deep learning models in wireless communication contexts. These findings are critical for deploying AMC models in security-sensitive applications.
    
    \item \textbf{Progressive Perturbation Analysis:} We systematically analyze the degradation in classification accuracy under varying levels of perturbation, providing insights into the model's resilience and guiding future developments in robust and interpretable AMC frameworks.
\end{itemize}

\section{Related Work}
AMC is pivotal in wireless communications, enabling the identification of modulation schemes for efficient signal processing and dynamic spectrum management. Traditional approaches, such as those using fourth-order cumulants [4] and ANNs [6], employed statistical analysis and hand-crafted features to identify modulation schemes. Azzouz and Nandi [6] developed decision criteria and signal processing methods for identifying different types of digital modulation, achieving a success rate of over 90\% at 10 dB SNR. While foundational, these methods often struggle with scalability and generalization under noisy conditions.

The advent of deep learning has revolutionized AMC, particularly with the introduction of Convolutional Neural Networks (CNNs). Peng et al. [2] leveraged CNN architectures to process constellation diagrams, achieving significant success on datasets like RadioML. These models introduced superior feature extraction capabilities compared to traditional methods but often lacked interpretability.

Residual Networks (ResNets) have further advanced AMC performance. Kumar et al. [7] demonstrated the robustness of ResNet architectures for AMC tasks by introducing a deep residual neural network that achieved high accuracy and resilience in noisy environments. The use of ResNets, which mitigate the problems of vanishing gradients in deep networks, has become a cornerstone in modern AMC pipelines.

Transformer-based models demonstrated state-of-the-art performance on datasets such as RadioML. Kong et al. [8] introduced a Vision Transformer (ViT)-based model that leverages self-attention mechanisms to capture global dependencies in input data, proving especially effective in handling noisy signals.

O'Shea et al. [9] explored over-the-air deep learning approaches for AMC, addressing real-world impairments such as carrier frequency offset and multipath fading. Their work highlighted the challenges in bridging the gap between synthetic datasets like RadioML and real-world signals. Similarly, Zhao et al. [10] proposed a meta-supervised contrastive learning framework to enhance AMC performance, particularly in few-shot and open-set scenarios.

Explainability in AMC has garnered significant attention, driven by the need to interpret and trust model decisions. Most AMC methods treat deep learning models as "black boxes," relying on post-hoc interpretability techniques such as Grad-CAM [11] and Integrated Gradients [12]. While effective, these approaches often lack the granularity needed to understand how specific signal features influence model decisions. Recent studies have highlighted the importance of explainability in AMC, emphasizing the need for integrated methods that offer transparency without compromising performance.

Perturbation-based techniques, widely used in other domains [13]–[15], provide a promising avenue for AMC. By systematically modifying input data, these methods evaluate the impact of specific features on model predictions. Methods such as LIME [14], XRAI [15], and meaningful perturbation [13] provide insights into how specific input features affect predictions. Wong and McPherson [5] introduced the use of concept bottleneck models, bridging the gap between performance and interpretability in AMC. These models first predict predefined concepts, which are then used for the final classification decision, offering inherent explanations for predictions. Our work builds on this foundation, integrating perturbation-based explainability into the AMC pipeline to provide actionable insights into the model's decision-making process.

\section{Proposed Approach}
\subsection{Conversion of I/Q Signals to Constellation Diagrams}
In digital communication systems, signals are represented using in-phase (I) and quadrature (Q) components, forming complex-valued time-domain samples. Constellation diagrams, which plot the I component on the x-axis and the Q component on the y-axis, provide a visual representation of the modulation scheme and serve as input for image-based deep learning models. This transformation has been widely adopted in modulation classification research due to its ability to reveal distinct patterns for different modulation types [2], [6].

\subsubsection{Transformation Steps}
The process of transforming raw I/Q signals into constellation diagrams is as follows:

\begin{enumerate}[(1)]
    \item \textbf{Binning:} The I and Q components, denoted as $I(i)$ and $Q(i)$ respectively in Eq. 1, are binned into a 224-by-224 grid. Scaling factors $s_I$ and $s_Q$ are applied to map the data into discrete bins as given in Eq. 1.
    \begin{equation}
        x = \frac{I(i) - I_{min}}{s_I}, y = \frac{Q(i) - Q_{min}}{s_Q}
    \end{equation}
    In Eq. 1, $I_{min}$ and $Q_{min}$ are the minimum values of the I and Q ranges. Also, $x$ and $y$ are the binned coordinates.
    
    \item \textbf{Smoothing:} A Gaussian smoothing filter is applied to the binned data to reduce noise as given in Eq. 2.
    \begin{equation}
        C_{smoothed}(x,y) = \sum_{i,j} C(i,j) \cdot G(x-i,y-j)
    \end{equation}
    In Eq. 2, $C(i,j)$ is the intensity at bin $(i,j)$, $G(x,y)$ is the Gaussian kernel and $C_{smoothed}(x,y)$ is the smoothed data.
    
    \item \textbf{Normalization:} As depicted in Eq. 3, the smoothed data is normalized to $C_{final}(x,y)$ so that the pixel intensity values are in the range [0, 255]:
    \begin{equation}
        C_{final}(x,y) = \frac{C_{smoothed}(x,y)}{\max(C_{smoothed})} \cdot 255
    \end{equation}
\end{enumerate}

\subsection{Model Architecture}
Our framework employs a multi-task learning approach with three distinct backbone architectures:

\subsubsection{ResNet-based Architecture}
The base architecture utilizes a ResNet18 backbone modified for single-channel input. The model consists of:
\begin{itemize}
    \item A modified first convolutional layer accepting grayscale input
    \item Shared ResNet18 backbone for feature extraction
    \item Task-specific heads for modulation and SNR classification
\end{itemize}

\subsubsection{Vision Transformer Architecture}
The Vision Transformer (ViT) variant employs:
\begin{itemize}
    \item Custom patch embedding for grayscale constellation diagrams
    \item Multi-head self-attention mechanism
    \item Task-specific attention layers for modulation and SNR
    \item Shared feature representation with specialized heads
\end{itemize}

\subsubsection{Swin Transformer Architecture}
The Swin Transformer implementation features:
\begin{itemize}
    \item Hierarchical feature maps with shifted windows
    \item Custom patch embedding for constellation data
    \item Multi-scale feature extraction
    \item Task-specific classification heads
\end{itemize}

\subsection{Multi-Task Learning Objective}
Our framework integrates modulation classification and SNR estimation using uncertainty-based loss weighting [16]. The architecture includes:

\begin{itemize}
    \item \textbf{Shared Backbone:} Feature extraction using one of the three architectures
    \item \textbf{Task-Specific Heads:} Separate classification layers for modulation and SNR
    \item \textbf{Uncertainty Weighting:} Dynamic loss balancing based on task uncertainty
\end{itemize}

The overall loss function $L_{total}$ combines the modulation classification loss $L_{modulation}$ and SNR estimation loss $L_{SNR}$ using learned uncertainty weights $\sigma_1$ and $\sigma_2$:

\begin{equation}
    L_{total} = \frac{1}{2\sigma_1^2}L_{modulation} + \frac{1}{2\sigma_2^2}L_{SNR} + \log(\sigma_1\sigma_2)
\end{equation}

The uncertainty weights $\sigma_1$ and $\sigma_2$ are learned parameters that automatically balance the contribution of each task based on their relative difficulty and uncertainty.

\subsection{Curriculum Learning}
To improve model performance across varying SNR conditions, we implement a curriculum learning strategy that progressively increases the difficulty of training samples:

\begin{enumerate}[(1)]
    \item \textbf{Initial Stage:} Training on high SNR samples (16-30 dB)
    \item \textbf{Intermediate Stage:} Including medium SNR samples (-2-14 dB)
    \item \textbf{Final Stage:} Full range of SNR values (-20-30 dB)
\end{enumerate}

The curriculum progression is controlled by a patience parameter that determines when to advance to the next stage based on validation performance.

\subsection{Justification of the Approach}
This approach leverages multiple architectural choices to capture different aspects of the constellation diagrams. The ResNet variant provides strong baseline performance, while the Vision Transformer and Swin Transformer architectures offer enhanced capability to capture global dependencies and hierarchical features. The uncertainty-based loss weighting ensures optimal task balancing, and the curriculum learning strategy enables robust performance across varying noise conditions.

\section{Explainability via Perturbation-Based Methods}
\subsection{Perturbation Methodology}
To understand the model's decision-making process, we employ a systematic perturbation analysis that examines how modifications to specific regions of the constellation diagrams affect classification performance. Our approach involves:

\begin{enumerate}[(1)]
    \item \textbf{Region Identification:} Dividing the constellation diagram into high-intensity and low-intensity regions based on signal energy distribution.
    \item \textbf{Progressive Perturbation:} Applying increasing levels of perturbation to identified regions.
    \item \textbf{Impact Analysis:} Measuring the effect of perturbations on classification accuracy and confidence.
\end{enumerate}

\subsection{Perturbation Impact Score}
We introduce the Perturbation Impact Score (PIS) to quantify the sensitivity of the model to perturbations in different regions:

\begin{equation}
    \text{PIS}(r, p) = \frac{A_0 - A_p}{A_0} \cdot \frac{1}{p}
\end{equation}

where $A_0$ is the baseline accuracy, $A_p$ is the accuracy after perturbation level $p$, and $r$ represents the region being perturbed. This score provides a normalized measure of how sensitive the model is to perturbations in different regions of the constellation diagram.

\subsection{Multi-Head Attention Analysis}
For the transformer-based architectures (ViT and Swin), we analyze the attention patterns to understand how the model processes different aspects of the constellation diagrams:

\begin{itemize}
    \item \textbf{Modulation-Specific Attention:} Examining how the model attends to constellation points characteristic of different modulation schemes.
    \item \textbf{SNR-Specific Attention:} Analyzing attention patterns related to noise and signal quality.
    \item \textbf{Cross-Task Attention:} Investigating how attention mechanisms share information between modulation and SNR tasks.
\end{itemize}

\subsection{Security Implications}
The perturbation analysis reveals important insights about the model's robustness and potential vulnerabilities:

\begin{itemize}
    \item \textbf{Adversarial Robustness:} Identification of regions most susceptible to adversarial attacks.
    \item \textbf{Noise Sensitivity:} Understanding how different types of noise affect model performance.
    \item \textbf{Defense Strategies:} Development of countermeasures based on identified vulnerabilities.
\end{itemize}

\subsection{Visualization and Interpretation}
To facilitate understanding of the model's behavior, we employ several visualization techniques:

\begin{itemize}
    \item \textbf{Attention Maps:} Visualizing attention patterns for transformer-based models.
    \item \textbf{Perturbation Heatmaps:} Showing regions of high sensitivity to perturbations.
    \item \textbf{Confidence Plots:} Tracking model confidence under different perturbation levels.
\end{itemize}

These visualizations provide intuitive insights into how the model processes constellation diagrams and makes classification decisions, enhancing the interpretability of the system.

\section{Experimental Results}
\subsection{Dataset and Training Setup}
We evaluate our framework on the RadioML 2018.01A dataset, which contains 11 modulation types and SNR values ranging from -20 dB to 30 dB. The dataset is split into training (70\%), validation (15\%), and test (15\%) sets. We implement curriculum learning with three stages, starting with high SNR samples and progressively including lower SNR values.

\subsection{Model Performance}
Table I presents the classification accuracy for each architecture across different SNR ranges. The Swin Transformer achieves the best overall performance, particularly in low SNR conditions, while the Vision Transformer shows competitive results with lower computational complexity.

\begin{table}[h]
\caption{Classification Accuracy (\%) Across SNR Ranges}
\centering
\begin{tabular}{lccc}
\hline
\textbf{Architecture} & \textbf{High SNR} & \textbf{Medium SNR} & \textbf{Low SNR} \\
\hline
ResNet18 & 95.2 & 88.7 & 75.3 \\
Vision Transformer & 96.1 & 90.2 & 78.5 \\
Swin Transformer & 97.3 & 92.8 & 82.1 \\
\hline
\end{tabular}
\end{table}

\subsection{Multi-Task Learning Analysis}
The uncertainty-based loss weighting effectively balances the modulation classification and SNR estimation tasks. Figure 1 shows the learned uncertainty weights $\sigma_1$ and $\sigma_2$ throughout training, demonstrating the dynamic adaptation to task difficulties.

\subsection{Perturbation Analysis Results}
Our perturbation analysis reveals several key findings:

\begin{itemize}
    \item High-intensity regions in constellation diagrams are more critical for modulation classification
    \item Low-intensity regions provide important information for SNR estimation
    \item The Swin Transformer shows greater robustness to perturbations compared to other architectures
\end{itemize}

Figure 2 illustrates the Perturbation Impact Scores (PIS) for different regions of the constellation diagrams, highlighting the varying sensitivity of the model to perturbations in different areas.

\subsection{Attention Pattern Analysis}
For transformer-based architectures, we observe distinct attention patterns:

\begin{itemize}
    \item Modulation-specific attention focuses on constellation points characteristic of each modulation scheme
    \item SNR-specific attention distributes more evenly across the diagram
    \item Cross-task attention shows strong correlation between modulation and SNR tasks
\end{itemize}

\subsection{Computational Efficiency}
Table II compares the computational requirements of each architecture:

\begin{table}[h]
\caption{Computational Requirements}
\centering
\begin{tabular}{lccc}
\hline
\textbf{Architecture} & \textbf{Parameters} & \textbf{FLOPs} & \textbf{Training Time} \\
\hline
ResNet18 & 11.7M & 1.8G & 1x \\
Vision Transformer & 86.4M & 2.3G & 1.5x \\
Swin Transformer & 88.0M & 2.5G & 1.7x \\
\hline
\end{tabular}
\end{table}

\section{Conclusion}
We have presented a comprehensive framework for Automatic Modulation Classification that combines multiple architectural approaches with advanced training strategies. The Swin Transformer architecture demonstrates superior performance, particularly in challenging SNR conditions, while the uncertainty-based loss weighting effectively balances the multi-task learning objectives. Our perturbation-based explainability analysis provides valuable insights into model behavior and robustness, contributing to the development of more interpretable and reliable AMC systems.

Future work will focus on:
\begin{itemize}
    \item Exploring hybrid architectures combining the strengths of different approaches
    \item Developing more sophisticated curriculum learning strategies
    \item Extending the explainability framework to real-world scenarios
    \item Investigating the application of these methods to other wireless communication tasks
\end{itemize}

\section*{Acknowledgment}
[To be added]

\bibliographystyle{IEEEtran}
\bibliography{references} 