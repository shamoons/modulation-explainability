\documentclass{ELSP}
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
	\usepackage[]{microtype}
	\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\IfFileExists{parskip.sty}{%
	\usepackage{parskip}
}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
	pdfcreator={ELSP}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
	\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{color}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{geometry}
\geometry{a4paper,top=2.5cm,bottom=1.9cm,left=1.75cm,right=1.75cm,headsep=12px}
\usepackage{float}
\usepackage{enumerate}
\usepackage{stfloats}
\usepackage{ragged2e}
\usepackage{titlesec}
% TikZ for diagrams
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,fit,shapes,calc}

\titleformat{\section}[hang]
  {\fontsize{12pt}{12pt}\selectfont\bfseries\color[RGB]{0,131,255}} 
  {\thesection}{0.5em}{}

\titleformat{\subsection}[hang]
  {\fontsize{12pt}{12pt}\selectfont\emph} 
  {\thesubsection}{0.5em}{}

\titleformat{\subsubsection}[hang]
  {\fontsize{12pt}{12pt}\selectfont} 
  {\thesubsubsection}{0.5em}{}

\setlength{\parindent}{2em}
\setlength{\baselineskip}{17pt}
\setlength{\parskip}{12pt}

%ELSP fancy
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{Research Article}}}
\fancyhead[L]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{ELSP Journal}}}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{1.4pt}
\fancypagestyle{firstpage}
{
	\fancyhf{}
	\setlength{\headsep}{6px}
	\fancyhead[R]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{ELSP}}}
	\fancyhead[L]{\sffamily \footnotesize \textbf{\textcolor[RGB]{0,131,255}{ELSP}}}
	\fancyfoot[L]{\sffamily \footnotesize Author {\em et al}. ELSP 2025: TBD}
	\renewcommand{\headrulewidth}{1.4pt}
}

\captionsetup{labelfont={bf},labelformat={default},labelsep=period,margin=4em,format=plain}

\begin{document}

\thispagestyle{firstpage}

\let\thefootnote\relax
\footnotetext{
\newline
\newline
	\begin{minipage}[h]{0.15\linewidth}
	\includegraphics{fig/cc.png}
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.8\linewidth}
		\footnotesize{Copyright©2025 by the authors. Published by ELSP. 
			This work is licensed under a Creative Commons Attribution 4.0 
			International License, which permits unrestricted use, distribution, 
			and reproduction in any medium provided the original work is properly cited}
	\end{minipage}
}

\setstretch{1.24}
\begin{flushleft}
{\sffamily \small \noindent {Research Article $\mid$ Received TBD; Accepted TBD; Published TBD}}\\
{\sffamily\small{https://doi.org/10.55092/xxxx}}

\papertitle{Constellation Diagram Augmentation and Perturbation-Based Explainability for Automatic Modulation Classification with SNR-Preserving Multi-Task Learning}

\authorname{Shamoon}{Siddiqui}{1}
\authorname{Huaxia}{Wang}{1}
\authornameCorres{Ravi P.}{Ramachandran}{1,}{*}

\formatintroduction{1}{Department of Electrical \& Computer Engineering, Rowan University, Glassboro, NJ, USA}

\authoremail{Correspondence author} {E-mail: ravi@rowan.edu. Co-authors: siddiq76@rowan.edu; wanghu@rowan.edu.}
\end{flushleft}

\noindent\textbf{\textcolor[RGB]{0,131,255}{Highlights:}}\\
\newline
\begin{itemize}
    \item Novel multi-task learning framework for joint modulation and SNR classification with constellation diagram augmentation
    \item First systematic perturbation-based explainability analysis revealing critical regions in constellation diagrams
    \item Enhanced constellation diagram generation methodology preserving signal characteristics
    \item Introduction of Perturbation Impact Score (PIS) metric for quantifying feature importance
    \item Comprehensive architecture evaluation revealing hierarchical attention superiority for constellation patterns
\end{itemize}

\noindent\textbf{\textcolor[RGB]{0,131,255}{Abstract:}} This paper presents the first blind joint modulation and SNR classification framework, combining constellation diagram augmentation with perturbation-based explainability for Automatic Modulation Classification (AMC). Unlike cascade approaches that perform sequential estimation, our multi-task learning architecture simultaneously classifies modulation schemes and estimates Signal-to-Noise Ratio (SNR) levels in a single unified model, without requiring any reference signals or oracle information, leveraging shared feature representations for improved generalization. We introduce systematic perturbation analysis of high- and low-intensity regions in constellation diagrams, quantifying their impact on classification accuracy using the novel Perturbation Impact Score (PIS) metric. Our investigation reveals critical preprocessing limitations in existing approaches, where standard per-image max normalization destroys SNR discriminative information. We propose literature-standard SNR-preserving constellation generation achieving 1.73x discrimination improvement. Through comprehensive evaluation across multiple architectures (ResNet, Vision Transformers, Swin Transformers), we demonstrate that hierarchical attention mechanisms are fundamentally superior for constellation pattern recognition, achieving 45.45\% combined accuracy on the challenging 272-class joint prediction task. The framework employs principled multi-task learning with Kendall uncertainty weighting, replacing ad-hoc loss balancing schemes. Perturbation analysis shows salient-region sensitivity (e.g., combined PIS $\approx 11.8$ at top 1\% masking) and minimal effect for random masking ($\approx 0$), providing actionable insights for model optimization and interpretability in safety-critical wireless communication applications.

\noindent\textbf{\textcolor[RGB]{0,131,255}{Keywords:}} automatic modulation classification, constellation diagrams, perturbation-based explainability, multi-task learning, SNR preservation, explainable AI, signal processing, deep learning

\section{Introduction and Motivation}

Automatic Modulation Classification (AMC) is a cornerstone in ensuring the adaptability and efficiency of modern wireless communication systems, enabling spectrum monitoring, cognitive radio applications, and electronic warfare systems. While traditional AMC approaches utilizing raw in-phase/quadrature (I/Q) time-series data have achieved significant success, constellation diagram-based methods offer unique advantages through visual pattern recognition capabilities that leverage the spatial geometry of modulated signals. However, despite high accuracy, these models often operate as ``black boxes''~\cite{koh2017understanding} which do not reveal the crucial steps used to reach a decision. This limited insight into their decision-making processes is a critical drawback in safety-critical applications where trust and transparency are paramount.

The growing need to understand and trust model decisions has driven interest in explainability techniques (comprehension of why an outcome is reached) for AMC. Recent advances in explainable AI have shown promise, but most approaches lack the granularity needed to understand how specific signal features influence model decisions. This gap in understanding limits the deployment of AMC models in high-stakes applications such as military communications, spectrum enforcement, and autonomous cognitive radio systems~\cite{rudin2019stop}, where decision transparency is essential for regulatory compliance and operational reliability.

Joint modulation classification and signal-to-Noise ratio (SNR) estimation addresses critical limitations of cascade approaches in modern wireless systems. Adaptive modulation and coding schemes require simultaneous knowledge of both modulation type and channel quality to optimize transmission parameters~\cite{dobre2007survey}. Cascade architectures that perform sequential estimation suffer from error propagation, where SNR estimation errors compound into modulation classification failures, degrading overall system performance~\cite{kendall2018multitask}. Recent work demonstrates that joint classification approaches can achieve up to 11.5\% accuracy improvement at 10 dB SNR compared to cascade methods by leveraging shared feature representations and avoiding intermediate decision boundaries~\cite{li2019curriculum}. Furthermore, single unified models reduce computational complexity and latency, critical factors for real-time cognitive radio applications.

Blind estimation without reference signals is essential for non-cooperative scenarios where prior channel information is unavailable. Electronic warfare and spectrum monitoring applications must operate without pilot symbols or training sequences, as adversarial or unauthorized transmitters provide no cooperation~\cite{dobre2007survey}. Reference signals impose significant overhead in satellite and long-range communications, reducing spectral efficiency and increasing latency in time-critical applications. Recent advances in blind estimation demonstrate robust performance even at ultra-low SNRs, with specialized methods achieving reliable single-parameter estimation at -35 dB for specific modulation types~\cite{wang2021duffing}. However, these approaches address isolated estimation tasks (e.g., carrier frequency for Binary Phase-Shift Keying), not the substantially harder problem of joint modulation and SNR classification across diverse modulation families that we tackle in this work. The elimination of reference requirements enables truly autonomous spectrum sensing and classification which are fundamental capabilities for next-generation cognitive radio systems.

The focus of this work is to advance the state-of-the-art through three fundamental directions.
\begin{enumerate}
    \item \textit{True joint classification} where both modulation type and SNR level are predicted simultaneously in a single unified model rather than cascade architectures.
    \item \textit{Completely blind operation} requiring no reference signals, oracle SNR labels, or auxiliary information as only constellation diagrams are used as input. 
    \item \textit{Explainability} is quantitatively assesed using perturbation analysis.
\end{enumerate}

We propose a novel framework that combines constellation diagram augmentation with perturbation-based explainability to enhance the accuracy, robustness (reliable performance on data distributions not seen during training), and interpretability of deep learning-based AMC models. The significance of this work extends beyond performance improvements to provide actionable insights into model behavior, enhancing trust and interpretability essential for deployment in safety-critical wireless communication environments. Our perturbation-based explainability framework offers transparency not available in existing AMC approaches, while maintaining competitive classification performance. The contributions of this investigation include:
\begin{enumerate}
    \item A novel multi-task learning framework 
    that simultaneously predicts modulation types and SNR levels, addressing the dual needs of modulation classification and channel quality estimation in real-world communication systems. 
    \item Introducing the Perturbation Impact Score (PIS) metric as a quantitative means to explore perturbation-based explainability for joint modulation-SNR prediction.
    \item Systematic investigation of the impact of perturbations on constellation diagrams thereby identifying critical regions that drive model predictions using the novel PIS metric. 
    \item Identification and correction of SNR information destruction in preprocessing (1.73x improvement). We identify critical preprocessing errors that destroy SNR discriminative information and propose literature-standard solutions.
    \item Comprehensive architecture evaluation revealing hierarchical attention superiority.
    \item Principled uncertainty weighting replacing ad-hoc loss balancing schemes.
\end{enumerate}

\section{Related Work}

This section summarizes the work related to the main aspects of this study.

\subsection{Constellation-Based Automatic Modulation Classification}

Constellation diagram representation has emerged as a powerful approach for AMC, leveraging computer vision techniques to analyze the spatial patterns of modulated signals. Early work by O'Shea \& Hoydis~\cite{oshea2017introduction} established the foundation for treating constellation diagrams as images suitable for convolutional neural networks. Recent advances have demonstrated the effectiveness of various preprocessing techniques, including power normalization and log scaling to enhance discriminative features~\cite{mendis2019augmentation,wang2020jointfeature}.

Zhang et al.~\cite{zhang2023multimodal} proposed a multi-modal approach combining time-domain signals with constellation diagrams, implementing SNR segmentation at -4 dB where constellation features become unreliable. Gao et al.~\cite{gao2023robust} evaluated constellation methods on bounded SNR ranges (-10 to 10 dB), demonstrating significant performance degradation at extreme SNRs. García-López et al.~\cite{garcia2024ultralight} achieved 96.3\% accuracy at 0 dB using constellation preprocessing but noted challenges below this threshold.

\subsection{Multi-Task Learning in Signal Processing}

Multi-task learning has shown promise for joint prediction problems in signal processing applications. Kendall et al.~\cite{kendall2018multitask} introduced homoscedastic uncertainty weighting for automatic loss balancing, providing principled approaches to multi-task optimization. Li et al.~\cite{li2019curriculum} demonstrated curriculum learning benefits for modulation classification, though focusing on single-task scenarios.

The challenge of joint modulation-SNR prediction has received limited attention in the literature. Most state of the art (SOTA) approaches either train separate models per SNR range or employ SNR-aware architectures with dynamic feature extraction~\cite{liu2020survey}. This work presents the first blind joint modulation and SNR classification framework that (1) simultaneously predicts both modulation type and SNR level from constellation diagrams, (2) does not employ any reference signals or oracle information and (3) utilizes principled uncertainty weighting.

\subsection{Transformer Architectures for Signal Classification}

The adoption of transformer architectures in signal processing has accelerated following successes in computer vision. Convolutional baselines such as ResNet provide strong shared-feature trunks for multi-task heads~\cite{he2016deep}. Vision Transformers (ViTs) have shown promise for AMC applications, though memory constraints and training instability remain as challenges~\cite{vit2020}. Swin Transformers introduce hierarchical processing and shifted window attention, offering computational efficiency while maintaining representational power~\cite{swin2021}.

Recent work has explored patch size optimization for signal classification, revealing that larger patch sizes provide efficiency benefits for macro-structural features typical in constellation patterns. However, systematic evaluation of transformer architectures specifically for constellation-based AMC remains limited, motivating our comprehensive architectural study.

\section{Methodology}

The strategies for multi-task learning and the explainability frameworks are discussed.

\subsection{Enhanced Constellation Diagram Generation}

We implement an enhanced constellation diagram generation methodology for in-phase/quadrature (I/Q) signal data transformation. The process converts complex-valued time-domain samples into visual representations suitable for image-based deep learning models. Our critical discovery revealed that standard preprocessing approaches destroy SNR information through per-image normalization, explaining persistent accuracy limitations in prior work.

\textbf{Power Normalization:} To maintain signal characteristics across different power levels, we define:

\begin{equation}
\text{power} = \frac{1}{N} \sum_{i=1}^{N} (I_i^2 + Q_i^2)
\end{equation}

\begin{equation}
\text{scale\_factor} = \sqrt{\text{power}}
\end{equation}

\begin{equation}
I_{normalized} = \frac{I}{\text{scale\_factor}}, \quad Q_{normalized} = \frac{Q}{\text{scale\_factor}}
\end{equation}

\textbf{Histogram Generation and Log Scaling:} The normalized I/Q data is binned into a two-dimensional (2D) histograms and log-scaled for enhanced dynamic range as given by:

\begin{equation}
H = \log(1 + \text{histogram2d}(I_{normalized}, Q_{normalized}))
\end{equation}

This approach maintains relative signal characteristics while providing enhanced visual representation of constellation patterns essential for multi-task learning across diverse SNR conditions.
Figure~\ref{fig:pipeline} summarizes the preprocessing and training flow used in our implementation.

% --------------------------------------------
% Figure: Constellation & Training Pipeline
% --------------------------------------------
\begin{figure}[t]
  \centering
  % Ensure the diagram fits within the page width
  \resizebox{0.95\linewidth}{!}{%
  \tikzset{>
    =Stealth,
    box/.style={draw, rounded corners=2pt, align=center, inner sep=4pt, outer sep=2pt, fill=white},
    proc/.style={box},
    data/.style={box, fill=gray!10},
    step/.style={box, fill=blue!3},
    head/.style={box, fill=green!5},
    group/.style={draw, rounded corners=4pt, inner sep=6pt, fit=#1}
  }
  \begin{tikzpicture}[node distance=6mm and 8mm]
    % Row 1: Data to Images
    \node[data] (iq) {Raw I/Q\newline (HDF5 / I,Q)};
    \node[proc, right=of iq] (power) {Power\newline Normalization\\$I,Q / \sqrt{\tfrac{1}{N}\sum(I^2+Q^2)}$};
    \node[proc, right=of power] (hist) {2D Histogram\\(I\_norm, Q\_norm)};
    \node[proc, right=of hist] (log) {Log Scaling\\$H=\log(1+\cdot)$};
    \node[data, right=of log] (img) {Constellation\newline Image (224$\times$224, gray)};
    \draw[->] (iq) -- (power);
    \draw[->] (power) -- (hist);
    \draw[->] (hist) -- (log);
    \draw[->] (log) -- (img);

    % Row 2: Dataset to Training
    \node[data, below=15mm of img] (dataset) {Dataset\newline (filtered mods, SNR 0--30 dB)};
    \node[proc, left=of dataset] (split) {Split\newline Train/Val/Test};
    \node[proc, left=of split] (loader) {DataLoader\newline (batch, shuffle)};
    \draw[->] (img) |- (dataset);
    \draw[->] (dataset) -- (split);
    \draw[->] (split) -- (loader);

    % Row 3: Model block
    \node[proc, below=15mm of split, minimum width=32mm] (backbone) {Backbone\\ResNet / Swin / ViT};
    \node[head, right=9mm of backbone, minimum width=28mm] (modhead) {Mod Head\\CE Loss};
    \node[head, right=9mm of modhead, minimum width=32mm] (snrhead) {SNR Head\\(standard / bottleneck)\\CE Loss};
    \draw[->] (loader) |- (backbone);
    \draw[->] (backbone) -- (modhead);
    \draw[->] (modhead) -- (snrhead);

    % Uncertainty + Optimization
    \node[step, below=10mm of modhead, minimum width=60mm] (uncert) {Analytical Uncertainty Weighting\\$L=\tfrac{1}{2\sigma^2_{m}}L_{mod}+\tfrac{1}{2\sigma^2_{s}}L_{snr}+\log(\sigma_m\sigma_s)$};
    \node[step, below=10mm of uncert, minimum width=60mm] (opt) {Optimizer (Adam) \,/\, Scheduler (cyclic/warmup)\\Early stopping, checkpoints, metrics};
    \draw[->] (modhead.south) |- (uncert.north);
    \draw[->] (snrhead.south) |- (uncert.north);
    \draw[->] (uncert) -- (opt);

    % Groups (visual cues)
    \node[group=(power)(hist)(log)] {};
    \node[group=(modhead)(snrhead)] {};
  \end{tikzpicture}%
  }% end resizebox
\caption{Constellation and training pipeline. Raw I/Q samples undergo power normalization, 2D histogramming, and log scaling to produce SNR-preserving constellation images. Images are filtered to 0--30 dB for training, loaded in batches, and passed through a shared backbone with task heads. Losses are combined via analytical uncertainty weighting and optimized with cyclic scheduling.}
\label{fig:pipeline}
\end{figure}

\subsection{Task-Specific Heads for Modulation and SNR}

After the shared backbone, we employ a lightweight task-specific extractor that decorrelates the feature streams before applying dedicated heads. The modulation branch uses a single linear classifier. The SNR branch can be configured with several variants: a standard linear projection, or bottlenecked heads that insert a fully-connected hidden layer prior to the final logits. In the bottleneck configurations, shared features are compressed to either 64 or 128 units (bottleneck\_64 and bottleneck\_128 respectively), followed by ReLU activation, dropout, and the final SNR classifier. This intermediate compression encourages the network to dedicate capacity to SNR-specific cues while limiting overfitting, and it empirically provided the most reliable convergence among the architectures we evaluated.

\subsection{Perturbation-Based Explainability Framework}

We integrate explainability directly into the AMC framework by employing systematic perturbation-based analysis. Perturbation-based methods systematically alter specific regions of the input to evaluate their impact on model predictions, offering insights into the model's decision-making process. This approach is particularly valuable in safety-critical domains, where understanding model behavior is paramount for trust and transparency.

\subsubsection{Perturbation Methodology}

We implement two key perturbation strategies designed to uncover critical features in constellation diagrams. The perturbation process uses percentile-based thresholds for intensity masking. Let $I(x,y)$ represent the intensity of pixel $(x,y)$ in the constellation diagram. For a given perturbation percentage $p$, the thresholds for masking are calculated as follows:

\textbf{Masking High-Intensity Regions (Top p\% Brightest Pixels):} The brightest regions of the constellation diagram, corresponding to the highest signal amplitudes, are identified and set to zero. Specifically, pixels with intensities higher than or equal to the $100-p$ percentile are masked by setting $I(x,y) = 0$.

\textbf{Masking Low-Intensity Non-Zero Regions (Bottom p\% Non-Zero Pixels):} The least bright but non-zero regions, representing subtle and often overlooked features, are identified and set to zero. Specifically, pixels with intensities that are greater than 0 and lower than or equal to the $p$ percentile are masked by setting $I(x,y) = 0$.

\subsubsection{Perturbation Impact Score (PIS) Metric}

To quantitatively assess the effects of perturbations, we introduce the Perturbation Impact Score (PIS) in Eqs. \ref{E:deltaA} and \ref{E:PIS}.

\begin{equation}
\Delta A = A_{original} - A_{perturbed}
\label{E:deltaA}
\end{equation}

\begin{equation}
PIS = \frac{\Delta A}{f}
\label{E:PIS}
\end{equation}

\noindent Note that $A_{original}$ is the accuracy prior to perturbation, $A_{perturbed}$ is the accuracy post-perturbation, $\Delta A$ is the change in accuracy, and $f$ represents the fraction of the input pixels that are perturbed (e.g., $f = 0.01$ for a 1\% mask). 
While \( \Delta A \) is generally expected to be positive (indicating a drop in accuracy due to perturbation), it is not guaranteed. If the perturbation improves performance, \( \Delta A \) could be negative.
Since \(f\) is the fraction of the perturbed input, it is always between 0 and 1.

The PIS quantitatively assesses the impact of perturbation. A high PIS can result if (1) \( \Delta A \) is high indicating a notable change in accuracy due to perturbation and/or (2) \(f\) is very low suggesting that even a small perturbation has a substantial effect on performance thereby highlighting the importance of the affected regions. The PIS metric provides a normalized measure of feature importance, enabling comparison across different perturbation scenarios.

Our approach is aligned with perturbation families such as Local Interpretable Model-agnostic Explanations (LIME) and Meaningful Perturbations, and black-box masking via Randomized Input Sampling for Explanation (RISE)~\cite{ribeiro2016lime,fong2017meaningful,petsiuk2018rise}. It complements gradient-based methods like Gradient-weighted Class Activation Mapping (Grad-CAM) and Integrated Gradients while observing reliability cautions~\cite{selvaraju2017grad,sundararajan2017ig,adebayo2018sanity,hooker2019roar}.
Figure~\ref{fig:perturbation_pipeline} provides an overview of perturbation generation, evaluation, and PIS computation.

% --------------------------------------------
% Figure: Perturbation & PIS Pipeline
% --------------------------------------------
\begin{figure}[t]
  \centering
  \resizebox{0.95\linewidth}{!}{%
  \tikzset{>
    =Stealth,
    box/.style={draw, rounded corners=2pt, align=center, inner sep=4pt, outer sep=2pt, fill=white},
    data/.style={box, fill=gray!10},
    proc/.style={box, fill=blue!3},
    calcbox/.style={box, fill=green!5},
  }
  \begin{tikzpicture}[node distance=6mm and 8mm]
    % Inputs
    \node[data] (imgs) {Constellation Images\\(0--30 dB)};
    \node[proc, right=of imgs] (masks) {Perturbation Masks\\Top p\% / Bottom p\% / Random p\%};
    \node[proc, right=of masks] (apply) {Apply Mask\\(pixel blackout)};
    \node[data, right=of apply] (pert) {Perturbed Dataset};
    \draw[->] (imgs) -- (masks);
    \draw[->] (masks) -- (apply);
    \draw[->] (apply) -- (pert);

    % Baseline branch
    \node[proc, below=12mm of imgs] (eval0) {Evaluate Baseline\\(Acc\_mod, Acc\_snr, Acc\_combined)};
    \draw[->] (imgs) -- (eval0);

    % Evaluation of perturbed
    \node[proc, below=12mm of pert] (evalp) {Evaluate Perturbed\\(Acc'\_mod, Acc'\_snr, Acc'\_combined)};
    \draw[->] (pert) -- (evalp);

    % PIS computation
    \node[calcbox, below=12mm of masks, minimum width=62mm] (pis) {Compute PIS\\$\Delta A = A - A'$,\; $\text{PIS} = \tfrac{\Delta A}{f}$};
    \draw[->] (eval0.east) -- ++(8mm,0) |- (pis.west);
    \draw[->] (evalp.west) -- ++(-8mm,0) |- (pis.east);

    % Outputs
    \node[data, below=12mm of pis] (plots) {PIS Summary \\\& Plots\\(degradation curves, bars)};
    \draw[->] (pis) -- (plots);
  \end{tikzpicture}%
  }% end resizebox
  \caption{Perturbation and PIS pipeline. Constellation images are perturbed by percentile-based masks (top, bottom, random). We evaluate baseline and perturbed accuracies to compute PIS given fraction $f$ of pixels masked, and visualize aggregated results.}
  \label{fig:perturbation_pipeline}
\end{figure}

\subsection{SNR Range Bounding Justification}

We employ a bounded SNR range (0--30 dB) based on extensive literature precedent and theoretical justification. Although all tooling in this work supports the full -20 to +30 dB span, the canonical experiments presented here focus on the 0--30 dB subset to ensure comparability with prior literature and operational SNR envelopes.

Our preprocessing pipeline can generate constellations for SNR levels from -20 to +30 dB in 2 dB steps sourced from the RadioML corpus~\cite{radioml2018}, yet we restrict training and evaluation to the 0--30 dB span to match common practice in constellation-based AMC studies and realistic deployment settings~\cite{peng2023constellation,garcia2024ultralight,zhang2023multimodal}. Recent work consistently demonstrates fundamental limitations below 0 dB~\cite{peng2023constellation,garcia2024ultralight}:

Zhang et al.~\cite{zhang2023multimodal} implement SNR segmentation at -4 dB, noting that constellation diagrams become "increasingly blurry" below -6 dB where "differences between modulation modes become almost impossible to distinguish." O'Shea \& West~\cite{oshea2016radioml} evaluated RadioML datasets primarily on 0-18 dB ranges, stating that "below 0 dB, constellation-based features become increasingly unreliable."

Information-theoretic analysis supports this approach. For an SNR below 0 dB (signal power < noise power), Shannon's channel capacity theorem indicates severe information loss. For constellation diagrams, this manifests as complete spatial randomization of constellation points and loss of geometric structure essential for visual classification. Our empirical evidence confirms F1 scores of 0.000 for SNRs in the -20 to -2 dB range, with optimal discrimination in the 0-14 dB range (F1 > 0.73); the F1 metric is defined formally in Section~\ref{sec:metrics}.

\subsection{Architecture Evaluation Framework}

We systematically evaluated multiple deep learning architectures for constellation-based AMC:

\textbf{Selected Architectures:}
\begin{itemize}
    \item ResNet18/34: Convolutional baselines (11-21M parameters)~\cite{he2016deep}
    \item Vision Transformer ViT-B/16, ViT-B/32: Global attention mechanisms (86M parameters)~\cite{vit2020}
    \item Swin Transformer Tiny/Small: Hierarchical attention (28-50M parameters)~\cite{liu2021swin}
    \item ViT-H/14: Large-scale boundary analysis (632M parameters)~\cite{vit2020}
\end{itemize}

Parameter-to-sample ratio analysis revealed optimal ranges for constellation classification. With 1.1M training samples (17 modulations × 16 SNRs × 4096 samples), models exceeding 100 parameters/sample show severe overfitting regardless of regularization techniques.

\subsection{Multi-Task Learning with Uncertainty Weighting}

We implement the homoscedastic uncertainty weighting framework introduced by Kendall et al.~\cite{kendall2018multitask} to balance modulation and SNR objectives as shown in Eq.\ref{E:Loss}.

\begin{equation}
\label{E:Loss}
L_{total} = \frac{1}{2\sigma_{mod}^2} L_{mod} + \frac{1}{2\sigma_{snr}^2} L_{snr} + \log(\sigma_{mod}\sigma_{snr})
\end{equation}

\noindent Note that $L_{total}$ is the combined loss function, $L_{mod}$ is the cross-entropy loss for modulation classification, and $L_{snr}$ is the cross-entropy loss for SNR classification. The quantities $\sigma_{mod}$ and $\sigma_{snr}$ are learned task uncertainties that automatically balance the two objectives. This principled formulation supplants manual α/β weighting and alleviates task competition by adapting to the relative difficulty of each objective. We additionally benchmarked alternative balancing strategies including GradNorm and dynamic weight averaging (DWA)~\cite{chen2018gradnorm,liu2019dwa}, but uncertainty weighting delivered the most stable training across our sweeps.

\section{Experimental Setup}

\subsection{Dataset and Preprocessing}

We utilize a comprehensive dataset of digital modulations across practical SNR ranges:
\begin{itemize}
    \item \textbf{Modulations:} 17 digital types (BPSK, QPSK, 8PSK, 16PSK, 32PSK, 4ASK, 8ASK, 16QAM, 32QAM, 64QAM, 128QAM, 256QAM, 16APSK, 32APSK, 64APSK, 128APSK, OQPSK)
    \item \textbf{SNR Range:} 0-30 dB in 2 dB steps (16 levels)
    \item \textbf{Total Classes:} 272 combinations (17 × 16)
    \item \textbf{Samples:} 1,114,112 total (4,096 per class)
    \item \textbf{Data Split:} 80\%/10\%/10\% train/validation/test with stratified splitting
\end{itemize}

Constellation diagrams are generated from I/Q signal data using 2D histogram binning with power normalization and log scaling for enhanced signal representation. Our investigation revealed that standard per-image max normalization destroys SNR discriminative information, achieving only 11-13\% SNR accuracy. The literature-standard approach preserves relative intensity differences, achieving 1.73x SNR discrimination improvement. Images are resized to 224×224 pixels for consistency with pretrained vision models.

\subsection{Training Configuration}

We employ standardized training configurations across all architectures:
\begin{itemize}
    \item \textbf{Optimization:} Adam optimizer with learning rate 1e-4
    \item \textbf{Regularization:} Dropout 0.3, weight decay 1e-5
    \item \textbf{Batch Size:} 256 (optimized for GPU utilization)
    \item \textbf{Early Stopping:} Patience 10 epochs on validation loss
    \item \textbf{Mixed Precision:} Enabled for CUDA devices
\end{itemize}

Bayesian hyperparameter optimization with Hyperband early termination guides architecture-specific parameter selection. All experiments use fixed random seeds for reproducibility.
Reported metrics are from single deterministic runs; expanding to multi-seed evaluations is left as future work to quantify variance more thoroughly.

\subsection{Evaluation Metrics}
\label{sec:metrics}

Primary evaluation focuses on combined accuracy (harmonic mean of modulation and SNR accuracy) to ensure balanced performance across both tasks. Secondary metrics include individual task accuracies, F1 scores for each class, confusion matrix analysis, and task weight evolution throughout training. The F1 score \cite{sokolova2009systematic} is defined as the harmonic mean of precision and recall and is between 0 and 1. The formula is given in Eq. \ref{E:F1}.
\begin{equation}
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\label{E:F1}
\end{equation}
The precision is the ratio of true positives to the total number of samples predicted as positive. The recall is the ratio of true positives to the total number of actual positive instances. The F1 score provides a balanced measure that accounts for both false positives and false negatives, and is particularly useful for imbalanced class distributions~\cite{sokolova2009systematic}.

\section{Results}

\subsection{Multi-Task Learning Performance}

The proposed multi-task learning framework achieves breakthrough performance on the challenging joint modulation-SNR prediction task. Using ResNet50 paired with the bottleneck\_128 SNR head (shared features $\rightarrow$ 128-unit compression $\rightarrow$ ReLU/Dropout $\rightarrow$ logits) and SNR-preserving constellation generation, we achieve:

\begin{itemize}
    \item \textbf{Combined Accuracy (primary):} 51.26\% on 272-class joint prediction (test set)
    \item \textbf{Modulation Accuracy:} 76.39\% across 17 digital modulation types  
    \item \textbf{SNR Accuracy:} 68.71\% across 16 SNR levels (0-30 dB)
    \item \textbf{Best Model:} Epoch 14 with minimal overfitting (51.03\% validation)
\end{itemize}

Secondary metrics including per-class F1 scores and task weight evolution are detailed below. Table~\ref{tab:sota} contextualizes these results against prior constellation-based AMC work; while modulation-only approaches achieve higher accuracies under favorable conditions, they do not address the substantially harder joint prediction problem that we tackle here.

\begin{table}[t]
\centering
\small
\begin{tabular}{lllllc}
\toprule
Setting & SNR (dB) & Formulation & Metric & Reported (\%) & Ref. \\
\midrule
Mod-only (constellation) & 0--20 & Single-task & Modulation acc. & 96.3 & \cite{garcia2024ultralight} \\
This work & 0--30 & Joint (272-class) & Combined acc. & 51.26 & --- \\
\bottomrule
\end{tabular}
\caption{Reported AMC results across settings. The modulation-only result (bounded SNR) is not directly comparable to true joint formulations but serves as context for task difficulty. This work presents the first blind joint modulation-SNR classification.}
\label{tab:sota}
\end{table}

Key observations include exceptional performance for simple schemes (BPSK: 100\%, QPSK: 94.7\%, 8ASK: 94.6\%), while complex schemes show expected challenges (256QAM: 50.7\%, 128QAM: 51.7\%). Figure~\ref{fig:f1_plots} illustrates this performance hierarchy through per-class F1 scores for both modulation types and SNR levels. The multi-task approach with uncertainty weighting achieves optimal task balance (76.6\% modulation / 23.4\% SNR weight allocation).

\subsection{Perturbation-Based Explainability Results}

Systematic perturbation analysis reveals critical insights into model decision-making processes:

\textbf{High-Intensity Region Impact:} Masking bright regions degrades performance. With 5\% of the brightest pixels perturbed, modulation accuracy drops from 76.39\% to 66.06\% (PIS $\approx 2.07$ on modulation; combined PIS $\approx 4.07$). At 1\% brightest, combined PIS is $\approx 11.75$.

\textbf{Low-Intensity Region Impact (most critical):} Perturbing the dimmest non-zero regions produces the largest degradation under our SNR-preserving, log-scaled images (combined PIS $\approx 48.67$ at 1\% dimmest; $\approx 9.72$ at 5\%). This indicates the model leverages low-intensity dispersion/background structure—particularly for SNR discrimination and for distinguishing higher-order modulations.

\textbf{PIS Trend Analysis:} Across perturbation sizes, bottom-pixel masking consistently yields the strongest accuracy loss (and highest PIS), top-pixel masking shows moderate impact (stronger for modulation than SNR), and random masking remains near zero or slightly negative. PIS decreases from 1\% to 5\% for both top and bottom masks, reflecting diminishing marginal importance as the masked area grows. Figure~\ref{fig:pis_plots} visualizes these perturbation effects across mask types and sizes.

\begin{figure}[t]
  \centering
  \begin{subfigure}[t]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/accuracy_degradation_curves.png}
    \caption{Accuracy degradation vs. mask size}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/pis_comparison_bar_chart.png}
    \caption{PIS by perturbation type}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/perturbation_impact_chart.png}
    \caption{Impact summary across tasks}
  \end{subfigure}
  \caption{Perturbation impact and PIS visualizations.}
  \label{fig:pis_plots}
\end{figure}

\begin{figure}[t]
  \centering
  \begin{subfigure}[t]{0.48\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/f1_modulation_bar.png}
    \caption{Per-class F1 (Modulation)}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/f1_snr_bar.png}
    \caption{Per-class F1 (SNR)}
  \end{subfigure}
  \caption{Per-class F1 scores for modulation types and SNR levels.}
  \label{fig:f1_plots}
\end{figure}

\subsection{Constellation Generation Impact}

The enhanced constellation diagram generation methodology demonstrates improved performance for joint modulation-SNR classification. The power normalization and log scaling approach provides enhanced visual representation of constellation patterns across diverse SNR conditions.

The impact of SNR-preserving constellation generation is dramatic:

\begin{itemize}
    \item \textbf{SNR Classification:} Significant improvement from baseline with proper preprocessing
    \item \textbf{Combined Accuracy:} 51.26\% test accuracy on 272-class joint prediction
    \item \textbf{SNR Discrimination:} 1.73x improvement in peak intensity ratio between high/low SNR signals
    \item \textbf{Training Stability:} Eliminated plateau at 24-26\% observed with SNR-destroying preprocessing
\end{itemize}

The improved preprocessing approach maintains signal characteristics essential for effective multi-task learning while providing robust visual features for both modulation and SNR classification tasks.

\subsection{Architecture Comparison}

Comprehensive evaluation across 500+ experimental runs reveals clear architectural hierarchy, summarized in Table~\ref{tab:arch}.

\begin{table}[t]
\centering
\small
\begin{tabular}{lcccc}
\toprule
Architecture & Parameters & Params/Sample & Best Combined Acc & Status \\
\midrule
ResNet18 & 11M & 8 & 23--26\% & Capacity ceiling \\
ResNet34 & 21M & 15 & 23--26\% & Capacity ceiling \\
ViT-B/16 & 86M & 61 & Memory limited & High overfitting \\
ViT-B/32 & 86M & 61 & Unstable & Training issues \\
Swin-Tiny & 28M & 20 & 45.45\% & Breakthrough \\
ResNet50 & 50M & 36 & 51.26\% & \textbf{Best} \\
ViT-H/14 & 632M & 451 & N/A & Extreme overfitting \\
\bottomrule
\end{tabular}
\caption{Architecture comparison across 500+ experimental runs. ResNet50 achieves best combined accuracy while Swin-Tiny demonstrates the breakthrough that established hierarchical attention superiority for constellation-based AMC.}
\label{tab:arch}
\end{table}

Hierarchical attention mechanisms demonstrate superior performance for constellation pattern recognition. Key architectural findings include:

\begin{itemize}
    \item \textbf{Training Stability:} Swin Transformer shows consistent convergence without instability observed in global attention ViTs
    \item \textbf{Memory Efficiency:} Hierarchical processing enables larger batch sizes compared to quadratic attention mechanisms  
    \item \textbf{Multi-Scale Learning:} Shifted window attention captures both local point clusters and global geometric arrangements
    \item \textbf{Parameter Efficiency:} 28M parameter Swin-Tiny achieves competitive performance with 20 params/sample ratio
\end{itemize}

\subsection{Multi-Task Learning Analysis}

The Kendall uncertainty weighting demonstrates exceptional effectiveness in balancing the multi-task objectives:

\begin{itemize}
    \item \textbf{Weight Convergence:} Learned task weights consistently favor modulation while retaining a substantive allocation for SNR
    \item \textbf{Task Balance Evolution:} Early epochs begin near uniform weighting and gradually bias toward the simpler modulation objective
    \item \textbf{Uncertainty Parameters:} Learned $\sigma$ values reflect the relative scale of each loss and remain stable once training equilibrates
    \item \textbf{Performance Impact:} Prevents SNR task starvation observed in fixed weighting experiments
\end{itemize}

Uncertainty weighting achieves improved task balance compared to fixed schemes. The learned parameters adapt automatically to the relative difficulty of modulation versus SNR classification, allowing both objectives to progress without extensive manual tuning.

\subsection{SNR Range Analysis}

Performance analysis across the 0-30 dB range confirms theoretical predictions and reveals the SNR-performance paradox:

\begin{itemize}
    \item \textbf{Optimal Range (0-14 dB):} F1 scores > 0.73, with peak at 0 dB (F1 = 0.920)
    \item \textbf{Mid-Range Excellence:} 2-12 dB maintains F1 > 0.80 through noise-induced constellation spreads
    \item \textbf{High-SNR Degradation:} 16-30 dB shows declining performance (F1: 0.65 → 0.31)
    \item \textbf{Over-Clarity Paradox:} Perfect signal conditions eliminate discriminative spread patterns
\end{itemize}

This counterintuitive finding suggests that noise itself serves as a discriminative feature for SNR classification in constellation-based approaches.

\section{Discussion}

\subsection{Perturbation-Based Explainability Insights}

Our perturbation analysis provides unprecedented insights into constellation-based AMC decision-making processes. The systematic investigation reveals that high-intensity regions are critical for modulation discrimination, with PIS values up to 34.8 for minimal (1\%) perturbations. This finding has significant implications for both model interpretability and robustness analysis in safety-critical wireless communication systems.

The diminishing PIS trend as perturbation percentage increases suggests that the most critical features are concentrated in the brightest constellation regions, corresponding to signal constellation points with highest amplitude. Low-intensity regions show minimal impact (PIS < 1.0), indicating that background noise contributes little to classification decisions. This validates the model's focus on geometrically meaningful signal features rather than artifacts.

These explainability insights enable actionable model optimization strategies, including targeted data augmentation focusing on critical high-intensity regions and robust training approaches that account for feature importance hierarchies revealed through perturbation analysis.

\subsection{SNR-Performance Paradox and Information Theory}

Our results reveal a counterintuitive relationship between signal clarity and classification difficulty. Mid-range SNRs (0-14 dB) consistently outperform both low and high SNRs, challenging assumptions that signal clarity correlates with classification ease. This "SNR-performance paradox" suggests that noise spread itself serves as a discriminative feature, providing spatial patterns absent in overly clean high-SNR signals.

The information-theoretic explanation centers on the loss of discriminative spatial patterns at extreme SNR conditions. At high SNRs, constellation points become indistinguishable dots lacking the spread patterns that enable visual discrimination between modulation schemes. This finding has profound implications for constellation-based AMC deployment in diverse channel conditions.

\subsection{Architectural Insights for Signal Processing}

The superiority of hierarchical attention for constellation classification aligns with the multi-scale nature of constellation patterns. Swin Transformer's shifted window mechanism provides computational efficiency while capturing both local point clusters and global geometric arrangements essential for modulation discrimination.

Parameter-to-sample ratio analysis establishes practical guidelines for model selection in constellation tasks. The 20 parameters/sample threshold for Swin-Tiny represents an optimal balance between capacity and overfitting risk for this domain, providing guidance for future architecture selection in signal processing applications.

\subsection{Multi-Task Learning and Explainability Integration}

Uncertainty weighting proves effective for balancing competing objectives in joint prediction scenarios while maintaining explainability. The learned task weights reflect inherent difficulty differences between modulation and SNR classification, providing automatic adaptation that improves over manual tuning approaches.

The integration of explainability with multi-task learning offers unique advantages: perturbation analysis can be applied independently to each task output, revealing task-specific feature importance patterns. This capability enables fine-grained understanding of how different constellation regions contribute to modulation versus SNR prediction, facilitating targeted model improvements.

\section{Limitations and Future Work}

Several limitations warrant acknowledgment. Our evaluation focuses on AWGN channel conditions; realistic channel effects (fading, interference) require future investigation. The bounded SNR range, while theoretically justified, may limit applicability to extreme operating conditions.

Future research directions include:
\begin{itemize}
    \item \textbf{Multi-Channel Extensions:} Three-channel constellation representations combining spatial, magnitude, and phase information
    \item \textbf{Family-Aware Architectures:} Multi-head design with specialized outputs for modulation families (ASK: 3 types, PSK: 6 types, QAM: 5 types, APSK: 4 types) to address representation competition
    \item \textbf{Adaptive Curriculum Learning:} Bounded hard-focus approach with momentum smoothing and safety constraints to prevent catastrophic forgetting
    \item \textbf{SNR-Guided Architecture:} Novel gradient detachment approach where SNR predictions guide modulation classification without backpropagation interference
    \item \textbf{Cascade vs Joint Prediction:} Comparative analysis of two-stage SNR estimation followed by SNR-specific modulation classifiers
    \item \textbf{Real-World Validation:} Over-the-air testing with hardware implementations under diverse channel conditions
\end{itemize}

\section{Conclusion}

This work presents a comprehensive framework combining constellation diagram augmentation with perturbation-based explainability for automatic modulation classification, addressing both performance and interpretability challenges in wireless communication systems. Our novel contributions advance the state-of-the-art through multiple significant innovations.

The introduction of systematic perturbation-based explainability with the Perturbation Impact Score (PIS) metric provides insights into constellation-based AMC decision-making. Our analysis shows strong sensitivity to targeted masking (e.g., combined PIS $\approx 11.75$ at top 1\%) and negligible impact for random masking, offering actionable guidance for model optimization and interpretability.

The development of enhanced constellation diagram generation methodology represents a critical advancement for signal processing applications. Our approach addresses fundamental limitations in preprocessing while enabling effective joint modulation-SNR classification.

The comprehensive architecture evaluation demonstrates the superiority of hierarchical attention mechanisms for constellation pattern recognition, providing theoretical and empirical justification for Swin Transformer adoption over traditional convolutional approaches. The principled multi-task learning framework with Kendall uncertainty weighting offers a systematic alternative to ad-hoc loss balancing schemes while maintaining explainability.

The integration of explainability with multi-task learning enables task-specific feature importance analysis, revealing how different constellation regions contribute to modulation versus SNR prediction. This capability facilitates targeted model improvements and provides transparency essential for deployment in safety-critical wireless communication environments.

This work represents the first blind joint modulation-SNR classification using constellation diagrams, achieving two fundamental advances: (1) true joint classification in a single unified model rather than cascade approaches, and (2) completely blind operation without any reference signals, oracle SNR labels, or auxiliary information. While existing SOTA approaches achieve 95\%+ accuracy on modulation-only classification with known SNR ranges, our 51.26\% combined accuracy on the 272-class blind joint prediction task establishes a new benchmark for this previously unexplored problem formulation. The framework demonstrates that high-performance AMC models can maintain transparency and interpretability without sacrificing accuracy, enabling trustworthy deployment in critical applications where understanding model decisions is paramount.

\section*{Acknowledgments}
 
The authors thank the Rowan University Department of Electrical \& Computer Engineering for computational resources and support.

\section*{Conflicts of Interests}

The authors declare no conflicts of interest.

\section*{Ethical statement}

This research involves computational analysis of synthetic signal data and does not require ethical approval.

\setlength{\parindent}{0em}
\bibliographystyle{aiasbst}
\bibliography{ref}
\end{document}
